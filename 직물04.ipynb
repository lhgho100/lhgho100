{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "connected-produce",
   "metadata": {},
   "source": [
    "### 모델 학습 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "extraordinary-tours",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.12.1-cp37-cp37m-manylinux2010_x86_64.whl (703 kB)\n",
      "\u001b[K     |████████████████████████████████| 703 kB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typeguard>=2.7\n",
      "  Downloading typeguard-2.11.1-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: typeguard, tensorflow-addons\n",
      "Successfully installed tensorflow-addons-0.12.1 typeguard-2.11.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "paperback-spain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Concatenate, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "devoted-basket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터\n",
    "EPOCHS = 1000\n",
    "RESULT_SAVE_PATH = 'dataset/results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-belarus",
   "metadata": {},
   "source": [
    "### Inception-base 모델정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "marine-allen",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model():\n",
    "    def inception(filters):\n",
    "        def subnetwork(x):\n",
    "            h1 = Conv2D(filters, (1, 1), padding='same', activation='relu')(x)\n",
    "            h1 = MaxPool2D()(h1)\n",
    "            \n",
    "            h2 = Conv2D(filters // 2, (1, 1), padding='same', activation='relu')(x)\n",
    "            h2 = Conv2D(filters, (3, 3), padding='same', activation='relu')(h2)\n",
    "            h2 = MaxPool2D()(h2)\n",
    "            \n",
    "            h3 = Conv2D(filters // 2, (1, 1), padding='same', activation='relu')(x)\n",
    "            h3 = Conv2D(filters, (5, 5), padding='same', activation='relu')(h3)\n",
    "            h3 = MaxPool2D()(h3)\n",
    "            return Concatenate()([h1, h2, h3])\n",
    "        return subnetwork\n",
    "    x = tf.keras.Input(shape=(256, 256, 3))\n",
    "    h = inception(16)(x)\n",
    "    h = inception(32)(h)\n",
    "    h = inception(32)(h)\n",
    "    h = inception(32)(h)\n",
    "    h = inception(32)(h)\n",
    "    h = Flatten()(h)\n",
    "    h = Dense(1024, activation='relu')(h)\n",
    "    y = Dense(1, activation='sigmoid')(h)\n",
    "    return tf.keras.Model(inputs=x, outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fitted-survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이타 전처리 함수\n",
    "def preprocess(img):\n",
    "    return tf.image.convert_image_dtype(img, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-speaker",
   "metadata": {},
   "source": [
    "### Data Augmentation 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "level-rehabilitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(img, label):\n",
    "    def flip(x):\n",
    "        x = tf.image.random_flip_left_right(x)\n",
    "        x = tf.image.random_flip_up_down(x)\n",
    "        return x\n",
    "    def rotate(x):\n",
    "        x = tf.cond(tf.random.uniform(shape=[], minval=0.0, maxval=1.0, dtype=tf.float32) > 0.5,\n",
    "                   lambda: tfa.image.rotate(x, \n",
    "                                            tf.random.uniform(shape=[], minval=0.0, maxval=360.0, dtype=tf.float32),\n",
    "                                            interpolation='BILINEAR'), \n",
    "                    lambda: x)\n",
    "        return x\n",
    "    def translation(x):\n",
    "        dx = tf.random.uniform(shape=[], minval=-10.0, maxval=10.0, dtype=tf.float32)\n",
    "        dy = tf.random.uniform(shape=[], minval=-10.0, maxval=10.0, dtype=tf.float32)\n",
    "        x = tf.cond(tf.random.uniform(shape=[], minval=0.0, maxval=1.0, dtype=tf.float32) > 0.5,\n",
    "                   lambda: tfa.image.transform(x, \n",
    "                                               [0, 0, dx, 0, 0, dy, 0, 0], \n",
    "                                               interpolation='BILINEAR'),\n",
    "                   lambda: x)\n",
    "        return x\n",
    "    img = flip(img)\n",
    "    img = rotate(img)\n",
    "    img = translation(img)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-investment",
   "metadata": {},
   "source": [
    "## TFRecords 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "minor-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "tffiles = glob.glob('dataset/tfrecords/*')\n",
    "raw_image_dataset = tf.data.TFRecordDataset(tffiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "veterinary-natural",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataset/tfrecords/00013.tfrecords'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tffiles[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "prescribed-coral",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_feature_description = {\n",
    "    'height': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'width': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "def _parse_image_label(parsed_dataset):\n",
    "    return preprocess(tf.image.decode_png(parsed_dataset['image_raw'])), parsed_dataset['label']\n",
    "\n",
    "parsed_image_dataset = raw_image_dataset.map(_parse_image_function)\n",
    "dataset = parsed_image_dataset.map(_parse_image_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-peeing",
   "metadata": {},
   "source": [
    "### 데이타셋 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "undefined-color",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_size = 0\n",
    "for _ in dataset:\n",
    "    ds_size += 1\n",
    "    \n",
    "train_size = int(ds_size * 0.7)\n",
    "ds = dataset.shuffle(ds_size)\n",
    "ds_train = ds.take(train_size).shuffle(1024, reshuffle_each_iteration=True).prefetch(1024).batch(32).map(augmentation)\n",
    "ds_valid = ds.skip(train_size).prefetch(1024).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guided-expense",
   "metadata": {},
   "source": [
    "## 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "defensive-classic",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-newcastle",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "broke-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-casino",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "55/55 [==============================] - 300s 3s/step - loss: 0.7224 - accuracy: 0.5047 - val_loss: 0.6801 - val_accuracy: 0.4462\n",
      "Epoch 2/1000\n",
      "55/55 [==============================] - 26s 333ms/step - loss: 0.6978 - accuracy: 0.4812 - val_loss: 0.6896 - val_accuracy: 0.5632\n",
      "Epoch 3/1000\n",
      "55/55 [==============================] - 25s 340ms/step - loss: 0.6952 - accuracy: 0.4789 - val_loss: 0.6913 - val_accuracy: 0.4758\n",
      "Epoch 4/1000\n",
      "55/55 [==============================] - 27s 344ms/step - loss: 0.6913 - accuracy: 0.5212 - val_loss: 0.6990 - val_accuracy: 0.4879\n",
      "Epoch 5/1000\n",
      "55/55 [==============================] - 25s 338ms/step - loss: 0.6943 - accuracy: 0.4949 - val_loss: 0.6921 - val_accuracy: 0.5121\n",
      "Epoch 6/1000\n",
      "55/55 [==============================] - 23s 317ms/step - loss: 0.6921 - accuracy: 0.5028 - val_loss: 0.6999 - val_accuracy: 0.9086\n",
      "Epoch 7/1000\n",
      "55/55 [==============================] - 26s 334ms/step - loss: 0.6946 - accuracy: 0.4888 - val_loss: 0.6811 - val_accuracy: 0.9355\n",
      "Epoch 8/1000\n",
      "55/55 [==============================] - 25s 318ms/step - loss: 0.6850 - accuracy: 0.5424 - val_loss: 0.6946 - val_accuracy: 0.4906\n",
      "Epoch 9/1000\n",
      "55/55 [==============================] - 25s 321ms/step - loss: 0.6943 - accuracy: 0.4970 - val_loss: 0.6927 - val_accuracy: 0.4812\n",
      "Epoch 10/1000\n",
      "55/55 [==============================] - 25s 341ms/step - loss: 0.6921 - accuracy: 0.5179 - val_loss: 0.6650 - val_accuracy: 0.8978\n",
      "Epoch 11/1000\n",
      "55/55 [==============================] - 30s 365ms/step - loss: 0.7584 - accuracy: 0.5973 - val_loss: 0.6822 - val_accuracy: 0.7191\n",
      "Epoch 12/1000\n",
      "55/55 [==============================] - 26s 349ms/step - loss: 0.6862 - accuracy: 0.5523 - val_loss: 0.6350 - val_accuracy: 0.8642\n",
      "Epoch 13/1000\n",
      "55/55 [==============================] - 26s 367ms/step - loss: 0.6533 - accuracy: 0.6069 - val_loss: 0.5782 - val_accuracy: 0.4704\n",
      "Epoch 14/1000\n",
      "55/55 [==============================] - 26s 358ms/step - loss: 0.7576 - accuracy: 0.5859 - val_loss: 1.0122 - val_accuracy: 0.5403\n",
      "Epoch 15/1000\n",
      "55/55 [==============================] - 24s 325ms/step - loss: 0.7247 - accuracy: 0.5181 - val_loss: 0.4084 - val_accuracy: 0.8750\n",
      "Epoch 16/1000\n",
      "55/55 [==============================] - 29s 364ms/step - loss: 0.5904 - accuracy: 0.6521 - val_loss: 0.6586 - val_accuracy: 0.5672\n",
      "Epoch 17/1000\n",
      "55/55 [==============================] - 25s 340ms/step - loss: 0.6457 - accuracy: 0.5972 - val_loss: 0.4139 - val_accuracy: 0.8911\n",
      "Epoch 18/1000\n",
      "55/55 [==============================] - 29s 383ms/step - loss: 0.5758 - accuracy: 0.6839 - val_loss: 0.2821 - val_accuracy: 0.9341\n",
      "Epoch 19/1000\n",
      "55/55 [==============================] - 26s 339ms/step - loss: 0.4754 - accuracy: 0.7331 - val_loss: 0.1369 - val_accuracy: 0.9637\n",
      "Epoch 20/1000\n",
      "55/55 [==============================] - 26s 365ms/step - loss: 0.6132 - accuracy: 0.6381 - val_loss: 0.6881 - val_accuracy: 0.4866\n",
      "Epoch 21/1000\n",
      "55/55 [==============================] - 25s 338ms/step - loss: 0.6859 - accuracy: 0.5527 - val_loss: 0.6155 - val_accuracy: 0.7433\n",
      "Epoch 22/1000\n",
      "55/55 [==============================] - 24s 323ms/step - loss: 0.6206 - accuracy: 0.7072 - val_loss: 0.4013 - val_accuracy: 0.9866\n",
      "Epoch 23/1000\n",
      "55/55 [==============================] - 23s 322ms/step - loss: 0.4965 - accuracy: 0.7375 - val_loss: 0.1088 - val_accuracy: 0.9758\n",
      "Epoch 24/1000\n",
      "55/55 [==============================] - 24s 315ms/step - loss: 0.5730 - accuracy: 0.6936 - val_loss: 0.2324 - val_accuracy: 0.9476\n",
      "Epoch 25/1000\n",
      "55/55 [==============================] - 24s 324ms/step - loss: 0.4751 - accuracy: 0.7535 - val_loss: 0.1910 - val_accuracy: 0.9651\n",
      "Epoch 26/1000\n",
      "55/55 [==============================] - 24s 327ms/step - loss: 0.7855 - accuracy: 0.7325 - val_loss: 0.8580 - val_accuracy: 0.4812\n",
      "Epoch 27/1000\n",
      "55/55 [==============================] - 23s 318ms/step - loss: 0.7036 - accuracy: 0.5822 - val_loss: 0.5306 - val_accuracy: 0.7984\n",
      "Epoch 28/1000\n",
      "55/55 [==============================] - 26s 354ms/step - loss: 0.6221 - accuracy: 0.6506 - val_loss: 0.4242 - val_accuracy: 0.9691\n",
      "Epoch 29/1000\n",
      "55/55 [==============================] - 27s 342ms/step - loss: 0.5728 - accuracy: 0.7224 - val_loss: 0.2919 - val_accuracy: 0.9153\n",
      "Epoch 30/1000\n",
      "55/55 [==============================] - 29s 393ms/step - loss: 0.5355 - accuracy: 0.7006 - val_loss: 0.1415 - val_accuracy: 0.9839\n",
      "Epoch 31/1000\n",
      "55/55 [==============================] - 27s 347ms/step - loss: 0.4421 - accuracy: 0.7600 - val_loss: 0.2524 - val_accuracy: 0.9207\n",
      "Epoch 32/1000\n",
      "55/55 [==============================] - 24s 300ms/step - loss: 0.5209 - accuracy: 0.6842 - val_loss: 0.1214 - val_accuracy: 0.9664\n",
      "Epoch 33/1000\n",
      "55/55 [==============================] - 26s 335ms/step - loss: 0.4604 - accuracy: 0.7281 - val_loss: 0.2629 - val_accuracy: 0.8938\n",
      "Epoch 34/1000\n",
      "55/55 [==============================] - 25s 307ms/step - loss: 0.5068 - accuracy: 0.6999 - val_loss: 0.6040 - val_accuracy: 0.5013\n",
      "Epoch 35/1000\n",
      "55/55 [==============================] - 25s 329ms/step - loss: 0.5766 - accuracy: 0.6676 - val_loss: 3.2375 - val_accuracy: 0.4812\n",
      "Epoch 36/1000\n",
      "55/55 [==============================] - 24s 338ms/step - loss: 0.8278 - accuracy: 0.5508 - val_loss: 0.3846 - val_accuracy: 0.9624\n",
      "Epoch 37/1000\n",
      "55/55 [==============================] - 26s 356ms/step - loss: 0.5747 - accuracy: 0.6777 - val_loss: 0.2336 - val_accuracy: 0.9368\n",
      "Epoch 38/1000\n",
      "55/55 [==============================] - 25s 344ms/step - loss: 0.4983 - accuracy: 0.6886 - val_loss: 0.1823 - val_accuracy: 0.9530\n",
      "Epoch 39/1000\n",
      "55/55 [==============================] - 25s 322ms/step - loss: 0.5578 - accuracy: 0.6656 - val_loss: 0.2932 - val_accuracy: 0.8911\n",
      "Epoch 40/1000\n",
      "55/55 [==============================] - 26s 352ms/step - loss: 0.4361 - accuracy: 0.7865 - val_loss: 0.2242 - val_accuracy: 0.9099\n",
      "Epoch 41/1000\n",
      "55/55 [==============================] - 22s 313ms/step - loss: 0.4548 - accuracy: 0.7279 - val_loss: 0.1850 - val_accuracy: 0.9704\n",
      "Epoch 42/1000\n",
      "55/55 [==============================] - 24s 333ms/step - loss: 0.3426 - accuracy: 0.8012 - val_loss: 0.2019 - val_accuracy: 0.9167\n",
      "Epoch 43/1000\n",
      "55/55 [==============================] - 25s 339ms/step - loss: 0.5938 - accuracy: 0.6136 - val_loss: 0.1830 - val_accuracy: 0.9476\n",
      "Epoch 44/1000\n",
      "55/55 [==============================] - 25s 319ms/step - loss: 0.4825 - accuracy: 0.7131 - val_loss: 0.1615 - val_accuracy: 0.9677\n",
      "Epoch 45/1000\n",
      "55/55 [==============================] - 25s 354ms/step - loss: 0.4908 - accuracy: 0.6863 - val_loss: 0.1657 - val_accuracy: 0.9543\n",
      "Epoch 46/1000\n",
      "55/55 [==============================] - 22s 304ms/step - loss: 0.6789 - accuracy: 0.6904 - val_loss: 0.1463 - val_accuracy: 0.9677\n",
      "Epoch 47/1000\n",
      "55/55 [==============================] - 25s 345ms/step - loss: 0.4228 - accuracy: 0.7406 - val_loss: 0.1549 - val_accuracy: 0.9543\n",
      "Epoch 48/1000\n",
      "55/55 [==============================] - 24s 323ms/step - loss: 0.3896 - accuracy: 0.7429 - val_loss: 0.1310 - val_accuracy: 0.9610\n",
      "Epoch 49/1000\n",
      "55/55 [==============================] - 23s 312ms/step - loss: 0.4282 - accuracy: 0.7515 - val_loss: 0.1578 - val_accuracy: 0.9718\n",
      "Epoch 50/1000\n",
      "55/55 [==============================] - 26s 356ms/step - loss: 0.3892 - accuracy: 0.7628 - val_loss: 0.1349 - val_accuracy: 0.9677\n",
      "Epoch 51/1000\n",
      "55/55 [==============================] - 24s 325ms/step - loss: 0.4235 - accuracy: 0.7494 - val_loss: 0.1193 - val_accuracy: 0.9798\n",
      "Epoch 52/1000\n",
      "55/55 [==============================] - 24s 320ms/step - loss: 0.3624 - accuracy: 0.7540 - val_loss: 0.1808 - val_accuracy: 0.9328\n",
      "Epoch 53/1000\n",
      "54/55 [============================>.] - ETA: 0s - loss: 0.3766 - accuracy: 0.7790"
     ]
    }
   ],
   "source": [
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, verbose=1)\n",
    "history = model.fit(ds_train, validation_data=ds_valid, epochs=EPOCHS, callbacks=[earlystopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-adelaide",
   "metadata": {},
   "source": [
    "### 학습 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-hazard",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(loss, 'ro-')\n",
    "plt.plot(val_loss, 'bo-')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-brand",
   "metadata": {},
   "source": [
    "## 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('dataset/inception_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
